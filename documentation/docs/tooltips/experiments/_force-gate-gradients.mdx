Whether to force the computation of gradients for the expert gate layers during training.

Note that setting this will disable quantization for the gate layers. It is also recommended to not specify the gate as a LoRA layer in this case (default).